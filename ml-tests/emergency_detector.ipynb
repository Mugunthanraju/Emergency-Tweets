{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Three For Twitter API Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watson NLU gives fear scores, and requires 1 API call each time\n",
    "# Sarcasm Detector is a standalone model, and can be pickle loaded.\n",
    "# NLP model for classification. Done after the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the three packages and pickle\n",
    "import classes\n",
    "import nlp_model\n",
    "import pickle as pk\n",
    "import watson_nlu\n",
    "import sarcasm_detector\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['today is gonna be a good good day nope sike']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate this in the first place.\n",
    "nlu_api = watson_nlu.get_ibm_nlu()\n",
    "clf, tv, ps, scores = sarcasm_detector.get_model()\n",
    "\n",
    "\n",
    "tweet = \"Today is gonna be a good good day. #Nope #Sike\"\n",
    "# Given a tweet as tweet.text (Later on I'll check a list of tweets. )\n",
    "print(watson_nlu.is_fearful(tweet, nlu_api))\n",
    "processed_tweets = sarcasm_detector.preprocess([tweet],ps)\n",
    "print(processed_tweets)\n",
    "clf.predict(tv.transform(processed_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# I know this is sarcastic -> Discard and Not Fearful -> Discard\n",
    "fear_matrix = [watson_nlu.is_fearful(tweet, nlu_api) for tweet in tweets]\n",
    "processed_tweets = sarcasm_detector.preprocess([tweet], ps)\n",
    "sarcasm_matrix = clf.predict(tv.transform(processed_tweets))\n",
    "result_matrix = [1 if (fear_matrix[i] and sarcasm_matrix[i]) else 0 for i in range(len(fear_matrix))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_eligible(tweets):\n",
    "    \"\"\"Given list of tweets as text return if emergent/eligible for a test 1, else 0.\n",
    "    If you want to pass only one tweet, add brackets tweet -> [tweet]\n",
    "    Returns: \n",
    "        1-0 matrix of len(tweets)\n",
    "    \"\"\"\n",
    "    fear_matrix = [watson_nlu.is_fearful(tweet, nlu_api) for tweet in tweets]\n",
    "    processed_tweets = sarcasm_detector.preprocess(tweets, ps)\n",
    "    sarcasm_matrix = clf.predict(tv.transform(processed_tweets))\n",
    "    return [1 if (fear_matrix[i] and not sarcasm_matrix[i]) else 0 for i in range(len(fear_matrix))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [\"tweet\", \"I am so afraid. The cops just shot a guy. He is bleeding\"]\n",
    "[watson_nlu.is_fearful(tweet, nlu_api) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "eligible_tweets = [tweet for i, tweet in enumerate([tweet]) if is_eligible([tweet])[i]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eligible_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emergent_tweets(tweets):\n",
    "    \"Returns: Emergent tweets with their corresponding Class.\"\n",
    "    eligible_tweets = [tweet for i, tweet in enumerate(tweets) if is_eligible(tweets)[i]]\n",
    "    return eligible_tweets, nlp_model.classify_list(eligible_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['I am so afraid. The cops just shot a guy. He is bleeding'], ['police'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emergent_tweets([\"tweet\", \"I am so afraid. The cops just shot a guy. He is bleeding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "\n",
    "# Watson NLU gives fear scores, and requires 1 API call each time\n",
    "# Sarcasm Detector is a standalone model, and can be pickle loaded.\n",
    "# NLP model for classification. Done after the other two.\n",
    "\n",
    "# Import the three packages and pickle\n",
    "import classes\n",
    "import nlp_model\n",
    "import pickle as pk\n",
    "import watson_nlu\n",
    "import sarcasm_detector\n",
    "import sys\n",
    "\n",
    "# Initiate this in the first place. Add to main\n",
    "nlu_api = watson_nlu.get_ibm_nlu()\n",
    "clf, tv, ps, scores = sarcasm_detector.get_model()\n",
    "\n",
    "\n",
    "def is_eligible(tweets):\n",
    "    \"\"\"Given list of tweets as text return if emergent/eligible for a test 1, else 0.\n",
    "    If you want to pass only one tweet, add brackets tweet -> [tweet]\n",
    "    Returns: \n",
    "        1-0 matrix of len(tweets)\n",
    "    \"\"\"\n",
    "    fear_matrix = [watson_nlu.is_fearful(tweet, nlu_api) for tweet in tweets]\n",
    "    processed_tweets = sarcasm_detector.preprocess(tweets, ps)\n",
    "    sarcasm_matrix = clf.predict(tv.transform(processed_tweets))\n",
    "    return [1 if (fear_matrix[i] and not sarcasm_matrix[i]) else 0 for i in range(len(fear_matrix))]\n",
    "\n",
    "def emergent_tweets(tweets):\n",
    "    \"Returns: Emergent tweets with their corresponding Class.\"\n",
    "    eligible_tweets = [tweet for i, tweet in enumerate(tweets) if is_eligible(tweets)[i]]\n",
    "    return eligible_tweets, nlp_model.classify_list(eligible_tweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

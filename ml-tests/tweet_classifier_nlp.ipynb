{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since now we have the tweets that are filtered based on sarcasm and fear, the next step is to create the actual model that classifies the data into medical emergency, life threats, and non-serious tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('life', 'danger', 'help')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The initial query\n",
    "\"life\",\"danger\",\"help\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords defined: Put these into a file, for later on use.\n",
    "# \"general\": \"trouble\", \"help\", \"save\", \"emergency\", \"support\", \"stuck\", \"tree\", \"send\"\n",
    "# \"police\": \"rescue\", \"assistme\", \"911\", \"robbery\", \"armed\", \"thief\", \"blast\", \"bomb\", \"run AND over\"\n",
    "# \"health\": \"urgent\" ,\"medicalassitence\",  \"exigency\",\"medicaid\", \"medicare\", \"ambulance\", \"medical\", \n",
    "# \"natural\": \"calamity\", \"flood\", \"landslide\", \"fire\", \"tsunami\", \"cyclone\", \"hurricane\", \"danger\", \"flashpoint\", \"blast\", \"outburst\"\n",
    "# \"road\": \"crash\", \"hitandrun\"\n",
    "# \"emergency\": \"emergency\" ,\"covid\" , \"rescue\" , \"ambulance\" , \"firefighter\" , \"paramedic\" , \"ems\" ,\"fire\" ,\n",
    "# \"coronavirus\" ,\"medical\" , \"feuerwehr\" ,\"emt\" ,\"hospital\" , \"firedepartment\" ,\"police\" ,\n",
    "# \"doctor\" ,\"nurse\",\"firstresponders\" ,\"firetruck\" ,\"bomberos\" ,\"medicine\", \"firefighters\" ,\"rettungsdienst\" ,\"emergenza\",\n",
    "# \"safety\",\"blaulicht\" ,\"fireman\" ,\"medic\", \"firefighting\", \"bhfyp\".\n",
    "\n",
    "classes = {\n",
    "\"non_serious\":\n",
    "    set([\"stuck\", \"traffic\", \"headache\",\n",
    "    \"trouble\", \"save\", \"support\",\n",
    "    \"tree\", \"misery\", \"save\"]),\n",
    "    \n",
    "\"police\": \n",
    "    set([\"run\", \"over\", \"crash\", \"gun\", \n",
    "    \"shot\", \"911\", \"robbery\",\n",
    "    \"broke in\", \"armed\", \"fire\",\n",
    "    \"now\", \"quick\", \"urgent\", \"bomb\",\n",
    "    \"robbed\", \"police\", \"fire\", \"dying\"]),\n",
    "    \n",
    "\"ambulance\":\n",
    "    set([\"bleeding\", \"blood\", \"breathe\",\n",
    "    \"emergency\", \"now\", \"quick\",\n",
    "    \"unconscious\",\"urgent\", \"ambulance\",\n",
    "    \"wounded\", \"dead\", \"die\", \"condition\"])\n",
    "}\n",
    "\n",
    "\n",
    "# non_serious = set([\"stuck\", \"traffic\", \"headache\",\n",
    "#                     \"trouble\", \"save\", \"support\",\n",
    "#                     \"tree\", \"misery\", \"save\"]),\n",
    "    \n",
    "# police = set([\"run over\", \"crash\", \"gun\", \n",
    "#     \"shot\", \"911\", \"robbery\",\n",
    "#     \"broke in\", \"armed\", \"fire\",\n",
    "#     \"now\", \"quick\", \"urgent\", \"bomb\",\n",
    "#     \"robbed\", \"police\", \"fire\"]),\n",
    "    \n",
    "# ambulance = set([\"bleeding\", \"blood\", \"breathe\",\n",
    "#     \"emergency\", \"now\", \"quick\",\n",
    "#     \"unconscious\",\"urgent\", \"ambulance\",\n",
    "#     \"wounded\", \"dead\", \"die\", \"condition\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hashtags, replace them with whitespace so we are left with words only. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Non-serious:\n",
    "I have my cat stuck on the tree \n",
    "Save me from my misery please. I need support.\n",
    "\n",
    "Police:\n",
    "A man is trying to run me over\n",
    "Please help me, my life is in danger\n",
    "A person just broke in my house. Please send help\n",
    "Just got a person #hitandrun I hit my head  \n",
    "\n",
    "Ambulance:\n",
    "My father can't breathe. He looks unconscious. Please send me help\n",
    "Please, please, please, help my dad. I don't want him to die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ambulance': 0, 'non_serious': 0, 'police': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given a sentence\n",
    "# sentence = \"This is a sentence. ambulance Non serious. tree #map #cantsaynotsay\"\n",
    "# sentence = \"I haven't feeling good lately. I think I am about to vomit\"\n",
    "sentence = \"I just saw a guy run over a man. Scary! #Police #CPD\" # This is a good example\n",
    "# Remove the hashtags\n",
    "# sentence.replace(\"#\",\"\").lower()\n",
    "sentence = re.sub('[^A-Za-z0-9 ]+', '', sentence).lower()\n",
    "# Get the weights from the sentence\n",
    "# print(ambulance)\n",
    "\n",
    "res = {}\n",
    "for cat in classes:\n",
    "    weight=0\n",
    "    for i in sentence.split():\n",
    "        if i in classes[cat]:\n",
    "            weight+=1\n",
    "    res[cat] = weight\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'police'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(res, key=res.get)# max(res[\"ambulance\"], res[\"non_serious\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i havent feeling good lately i think i am about to vomit'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sklearn as sk\n",
    "from classes import classes \n",
    "\n",
    "\n",
    "# Classes taken from classes.py\n",
    "def classify(sentence):\n",
    "    # Remove the hashtags\n",
    "    sentence = re.sub('[^A-Za-z0-9 ]+', '', sentence).lower()\n",
    "    # Get the weights from the sentence\n",
    "    res = {}\n",
    "    for cat in classes:\n",
    "        weight=0\n",
    "        for i in sentence.split():\n",
    "            if i in classes[cat]:\n",
    "                weight+=1\n",
    "        res[cat] = weight\n",
    "    # Return most weight\n",
    "    return max(res, key=res.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non_serious'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"I don't like working here with you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean code\n",
    "\n",
    "import re\n",
    "import sklearn as sk\n",
    "from classes import classes # Categories taken from classes.py\n",
    "\n",
    "\n",
    "def classify(sentence):\n",
    "    \"\"\"Given a sentence check the signals from the categories to classify\n",
    "    the corresponding class.\n",
    "    Returns:\n",
    "        Class name with most weight as String\n",
    "    \"\"\"\n",
    "    # Remove the hashtags\n",
    "    sentence = re.sub('[^A-Za-z0-9 ]+', '', sentence).lower()\n",
    "    # Get the weights from the sentence\n",
    "    res = {}\n",
    "    for cat in classes:\n",
    "        weight=0\n",
    "        for i in sentence.split():\n",
    "            if i in classes[cat]:\n",
    "                weight+=1\n",
    "        res[cat] = weight\n",
    "    # Return most weight\n",
    "    return max(res, key=res.get)\n",
    "\n",
    "def classify_list(sentence_list):\n",
    "    \"\"\"Iteration over multiple sentences.\n",
    "    Returns:\n",
    "        Classes as a list of Strings\n",
    "    \"\"\"\n",
    "    return [classify(x.test) for x in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non_serious', 'non_serious', 'police']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_list([\"ali\", \"I don't like nothing\", \"I am dying help\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
